{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ee7e72",
   "metadata": {},
   "source": [
    "# Linear-Log Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c81a31",
   "metadata": {},
   "source": [
    "## 0.导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a527a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c654ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83e0ba",
   "metadata": {},
   "source": [
    "## 1.数据导入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0414798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"ag_news_csv/train.csv\", header=None, names=[\"label\", \"title\", \"description\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19be632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title  \\\n",
      "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
      "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
      "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
      "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
      "4      3  Oil prices soar to all-time record, posing new...   \n",
      "\n",
      "                                         description  \n",
      "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
      "1  Reuters - Private investment firm Carlyle Grou...  \n",
      "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
      "3  Reuters - Authorities have halted oil export\\f...  \n",
      "4  AFP - Tearaway world oil prices, toppling reco...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e61a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_space(word):\n",
    "    return re.sub(r\"[-\\\\/&]\", \" \", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a10161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(replace_space)\n",
    "df[\"description\"] = df[\"description\"].apply(replace_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e3258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_num(word):\n",
    "    return re.sub(r\"\\d+\", \"<NUM>\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34327eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(replace_num)\n",
    "df[\"description\"] = df[\"description\"].apply(replace_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff6c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_num(word):\n",
    "    return re.sub(r\"(<NUM>)\", r\" \\1 \", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcfe480",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(separate_num)\n",
    "df[\"description\"] = df[\"description\"].apply(separate_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4740dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                              title  \\\n",
      "0           3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
      "1           3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
      "2           3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
      "3           3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
      "4           3  Oil prices soar to all time record, posing new...   \n",
      "...       ...                                                ...   \n",
      "119995      1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
      "119996      2                  Renteria signing a top shelf deal   \n",
      "119997      2                    Saban not going to Dolphins yet   \n",
      "119998      2                                  Today's NFL games   \n",
      "119999      2                       Nets get Carter from Raptors   \n",
      "\n",
      "                                              description  \n",
      "0       Reuters   Short sellers, Wall Street's dwindli...  \n",
      "1       Reuters   Private investment firm Carlyle Grou...  \n",
      "2       Reuters   Soaring crude prices plus worries ab...  \n",
      "3       Reuters   Authorities have halted oil export f...  \n",
      "4       AFP   Tearaway world oil prices, toppling reco...  \n",
      "...                                                   ...  \n",
      "119995   KARACHI (Reuters)   Pakistani President Perve...  \n",
      "119996  Red Sox general manager Theo Epstein acknowled...  \n",
      "119997  The Miami Dolphins will put their courtship of...  \n",
      "119998  PITTSBURGH at NY GIANTS Time:  <NUM> : <NUM>  ...  \n",
      "119999  INDIANAPOLIS    All Star Vince Carter was trad...  \n",
      "\n",
      "[120000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f023cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0987f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"title\"].apply(tokenize) + df[\"description\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31950454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [Wall, St., Bears, Claw, Back, Into, the, Blac...\n",
      "1         [Carlyle, Looks, Toward, Commercial, Aerospace...\n",
      "2         [Oil, and, Economy, Cloud, Stocks', Outlook, (...\n",
      "3         [Iraq, Halts, Oil, Exports, from, Main, Southe...\n",
      "4         [Oil, prices, soar, to, all, time, record,, po...\n",
      "                                ...                        \n",
      "119995    [Pakistan's, Musharraf, Says, Won't, Quit, as,...\n",
      "119996    [Renteria, signing, a, top, shelf, deal, Red, ...\n",
      "119997    [Saban, not, going, to, Dolphins, yet, The, Mi...\n",
      "119998    [Today's, NFL, games, PITTSBURGH, at, NY, GIAN...\n",
      "119999    [Nets, get, Carter, from, Raptors, INDIANAPOLI...\n",
      "Name: tokens, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e40322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"description\", axis=1, inplace=True)\n",
    "df.drop(\"title\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac1078da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                             tokens\n",
      "0           3  [Wall, St., Bears, Claw, Back, Into, the, Blac...\n",
      "1           3  [Carlyle, Looks, Toward, Commercial, Aerospace...\n",
      "2           3  [Oil, and, Economy, Cloud, Stocks', Outlook, (...\n",
      "3           3  [Iraq, Halts, Oil, Exports, from, Main, Southe...\n",
      "4           3  [Oil, prices, soar, to, all, time, record,, po...\n",
      "...       ...                                                ...\n",
      "119995      1  [Pakistan's, Musharraf, Says, Won't, Quit, as,...\n",
      "119996      2  [Renteria, signing, a, top, shelf, deal, Red, ...\n",
      "119997      2  [Saban, not, going, to, Dolphins, yet, The, Mi...\n",
      "119998      2  [Today's, NFL, games, PITTSBURGH, at, NY, GIAN...\n",
      "119999      2  [Nets, get, Carter, from, Raptors, INDIANAPOLI...\n",
      "\n",
      "[120000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb29cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(tokens):\n",
    "    return [word.lower() for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16df5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"tokens\"].apply(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c34143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [wall, st., bears, claw, back, into, the, blac...\n",
      "1         [carlyle, looks, toward, commercial, aerospace...\n",
      "2         [oil, and, economy, cloud, stocks', outlook, (...\n",
      "3         [iraq, halts, oil, exports, from, main, southe...\n",
      "4         [oil, prices, soar, to, all, time, record,, po...\n",
      "                                ...                        \n",
      "119995    [pakistan's, musharraf, says, won't, quit, as,...\n",
      "119996    [renteria, signing, a, top, shelf, deal, red, ...\n",
      "119997    [saban, not, going, to, dolphins, yet, the, mi...\n",
      "119998    [today's, nfl, games, pittsburgh, at, ny, gian...\n",
      "119999    [nets, get, carter, from, raptors, indianapoli...\n",
      "Name: tokens, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8a1407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word_suffixes(word):\n",
    "    if word.endswith(\"'s\"):\n",
    "        word = word[:-2]\n",
    "    # elif word.endswith(\"s\"):\n",
    "    #    word = word[:-1]\n",
    "    else:\n",
    "        return re.sub(r'[.,:()\\'\"?;#$!]', \"\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a603e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffixes(tokens):\n",
    "    return [remove_word_suffixes(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03e3cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"tokens\"].apply(remove_suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124bd72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [wall, st, bears, claw, back, into, the, black...\n",
      "1         [carlyle, looks, toward, commercial, aerospace...\n",
      "2         [oil, and, economy, cloud, stocks, outlook, re...\n",
      "3         [iraq, halts, oil, exports, from, main, southe...\n",
      "4         [oil, prices, soar, to, all, time, record, pos...\n",
      "                                ...                        \n",
      "119995    [None, musharraf, says, wont, quit, as, army, ...\n",
      "119996    [renteria, signing, a, top, shelf, deal, red, ...\n",
      "119997    [saban, not, going, to, dolphins, yet, the, mi...\n",
      "119998    [None, nfl, games, pittsburgh, at, ny, giants,...\n",
      "119999    [nets, get, carter, from, raptors, indianapoli...\n",
      "Name: tokens, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b57e1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if (word not in stopwords) and (word is not None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f589bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\") as file:\n",
    "    stopwords = file.read().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e45ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'A', 'about', 'above', 'across', 'after', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'an', 'and', 'another', 'any', 'anyone', 'anything', 'anywhere', 'are', \"aren't\", 'around', 'as', 'at', 'b', 'B', 'back', 'be', 'became', 'because', 'become', 'becomes', 'been', 'before', 'behind', 'being', 'below', 'between', 'both', 'but', 'by', 'c', 'C', 'can', 'cannot', \"can't\", 'could', \"couldn't\", 'd', 'D', 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', 'done', \"don't\", 'down', 'during', 'e', 'E', 'each', 'either', 'enough', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'f', 'F', 'few', 'find', 'first', 'for', 'four', 'from', 'full', 'further', 'g', 'G', 'get', 'give', 'go', 'h', 'H', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', \"here's\", 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'however', \"how's\", 'i', 'I', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'interest', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"i've\", 'j', 'J', 'k', 'K', 'keep', 'l', 'L', 'last', 'least', 'less', \"let's\", 'made', 'many', 'may', 'me', 'might', 'more', 'most', 'mostly', 'much', 'must', \"mustn't\", 'my', 'myself', 'n', 'N', 'never', 'next', 'no', 'nobody', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'o', 'O', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'or', 'other', 'others', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'p', 'P', 'part', 'per', 'perhaps', 'put', 'q', 'Q', 'r', 'R', 'rather', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'several', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'show', 'side', 'since', 'so', 'some', 'someone', 'something', 'somewhere', 'still', 'such', 't', 'T', 'take', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'therefore', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'though', 'three', 'through', 'thus', 'to', 'together', 'too', 'toward', 'two', 'u', 'U', 'under', 'until', 'up', 'upon', 'us', 'v', 'V', 'very', 'w', 'W', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"won't\", 'well', \"we're\", 'were', \"weren't\", \"we've\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'whether', 'which', 'while', 'who', 'whole', 'whom', \"who's\", 'whose', 'why', \"why's\", 'will', 'with', 'within', 'without', \"won't\", 'would', \"wouldn't\", 'x', 'X', 'y', 'Y', 'yet', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\", 'z', 'Z', '--', '']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efb3e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"tokens\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89b23148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [wall, st, bears, claw, black, reuters, reuter...\n",
      "1         [carlyle, looks, commercial, aerospace, reuter...\n",
      "2         [oil, economy, cloud, stocks, outlook, reuters...\n",
      "3         [iraq, halts, oil, exports, main, southern, pi...\n",
      "4         [oil, prices, soar, time, record, posing, new,...\n",
      "                                ...                        \n",
      "119995    [musharraf, says, wont, quit, army, chief, kar...\n",
      "119996    [renteria, signing, top, shelf, deal, red, sox...\n",
      "119997    [saban, going, dolphins, miami, dolphins, cour...\n",
      "119998    [nfl, games, pittsburgh, ny, giants, time, <nu...\n",
      "119999    [nets, carter, raptors, indianapolis, star, vi...\n",
      "Name: tokens, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db418b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76a7bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_pos(tokens):\n",
    "    pos_tagged = pos_tag(tokens)\n",
    "    return [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tagged\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d952b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(lemmatize_with_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47e1436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [wall, st, bear, claw, black, reuters, reuters...\n",
      "1         [carlyle, look, commercial, aerospace, reuters...\n",
      "2         [oil, economy, cloud, stock, outlook, reuters,...\n",
      "3         [iraq, halt, oil, export, main, southern, pipe...\n",
      "4         [oil, price, soar, time, record, pose, new, me...\n",
      "                                ...                        \n",
      "119995    [musharraf, say, wont, quit, army, chief, kara...\n",
      "119996    [renteria, sign, top, shelf, deal, red, sox, g...\n",
      "119997    [saban, go, dolphin, miami, dolphin, courtship...\n",
      "119998    [nfl, game, pittsburgh, ny, giant, time, <num>...\n",
      "119999    [net, carter, raptor, indianapolis, star, vinc...\n",
      "Name: tokens, Length: 120000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff479de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"processed_train_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5b0b4",
   "metadata": {},
   "source": [
    "## 2.TF-IDF编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd19ad1f-b00b-437a-b1ee-c6b922f2d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"processed_train_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a22b05-9203-48d9-9c89-3230252dcf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                             tokens\n",
      "0           3  [wall, st, bear, claw, black, reuters, reuters...\n",
      "1           3  [carlyle, look, commercial, aerospace, reuters...\n",
      "2           3  [oil, economy, cloud, stock, outlook, reuters,...\n",
      "3           3  [iraq, halt, oil, export, main, southern, pipe...\n",
      "4           3  [oil, price, soar, time, record, pose, new, me...\n",
      "...       ...                                                ...\n",
      "119995      1  [musharraf, say, wont, quit, army, chief, kara...\n",
      "119996      2  [renteria, sign, top, shelf, deal, red, sox, g...\n",
      "119997      2  [saban, go, dolphin, miami, dolphin, courtship...\n",
      "119998      2  [nfl, game, pittsburgh, ny, giant, time, <num>...\n",
      "119999      2  [net, carter, raptor, indianapolis, star, vinc...\n",
      "\n",
      "[120000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b668aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_counter = Counter()\n",
    "for tokens in df[\"tokens\"]:\n",
    "    words_counter.update(tokens)\n",
    "vocabulary = dict(words_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3380b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall: 1500\n",
      "st: 1679\n",
      "bear: 722\n",
      "claw: 36\n",
      "black: 836\n",
      "reuters: 17270\n",
      "short: 924\n",
      "seller: 105\n",
      "dwindle: 48\n",
      "band: 240\n",
      "ultra: 81\n",
      "cynic: 6\n",
      "see: 1861\n",
      "green: 864\n",
      "carlyle: 16\n",
      "look: 2786\n",
      "commercial: 541\n",
      "aerospace: 129\n",
      "private: 721\n",
      "investment: 986\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key, value in vocabulary.items():\n",
    "    if counter < 20:\n",
    "        print(f\"{key}: {value}\")\n",
    "        counter += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86459566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(tokens):\n",
    "    tf = Counter(tokens)\n",
    "    for i in tf:\n",
    "        tf[i] = (1 + math.log10(tf[i])) if tf[i] != 0 else 0\n",
    "    return dict(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6373e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = [compute_tf(tokens) for tokens in df[\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f3046f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wall': 1.3010299956639813, 'st': 1.0, 'bear': 1.0, 'claw': 1.0, 'black': 1.0, 'reuters': 1.3010299956639813, 'short': 1.0, 'seller': 1.0, 'dwindle': 1.0, 'band': 1.0, 'ultra': 1.0, 'cynic': 1.0, 'see': 1.0, 'green': 1.0}\n",
      "{'carlyle': 1.3010299956639813, 'look': 1.0, 'commercial': 1.0, 'aerospace': 1.0, 'reuters': 1.3010299956639813, 'private': 1.0, 'investment': 1.0, 'firm': 1.0, 'group': 1.0, 'reputation': 1.0, 'make': 1.0, 'time': 1.0, 'occasionally': 1.0, 'controversial': 1.0, 'play': 1.0, 'defense': 1.0, 'industry': 1.0, 'quietly': 1.0, 'place': 1.0, 'bet': 1.0, 'market': 1.0}\n",
      "{'oil': 1.0, 'economy': 1.3010299956639813, 'cloud': 1.0, 'stock': 1.3010299956639813, 'outlook': 1.3010299956639813, 'reuters': 1.3010299956639813, 'soar': 1.0, 'crude': 1.0, 'price': 1.0, 'plus': 1.0, 'worry': 1.0, 'earnings': 1.0, 'expect': 1.0, 'hang': 1.0, 'market': 1.0, 'week': 1.0, 'depth': 1.0, 'summer': 1.0, 'doldrums': 1.0}\n",
      "{'iraq': 1.3010299956639813, 'halt': 1.3010299956639813, 'oil': 1.4771212547196624, 'export': 1.3010299956639813, 'main': 1.3010299956639813, 'southern': 1.3010299956639813, 'pipeline': 1.3010299956639813, 'reuters': 1.3010299956639813, 'authority': 1.0, 'flow': 1.0, 'intelligence': 1.0, 'show': 1.0, 'rebel': 1.0, 'militia': 1.0, 'strike': 1.0, 'infrastructure': 1.0, 'official': 1.0, 'say': 1.0, 'saturday': 1.0}\n",
      "{'oil': 1.3010299956639813, 'price': 1.3010299956639813, 'soar': 1.0, 'time': 1.0, 'record': 1.3010299956639813, 'pose': 1.0, 'new': 1.3010299956639813, 'menace': 1.3010299956639813, 'economy': 1.0, 'afp': 1.3010299956639813, 'tearaway': 1.0, 'world': 1.0, 'toppling': 1.0, 'strain': 1.0, 'wallet': 1.0, 'present': 1.0, 'economic': 1.0, 'barely': 1.0, 'month': 1.0, 'presidential': 1.0, 'election': 1.0}\n",
      "{'stock': 1.3010299956639813, 'end': 1.3010299956639813, 'near': 1.3010299956639813, 'year': 1.3010299956639813, 'low': 1.3010299956639813, 'reuters': 1.3010299956639813, 'slightly': 1.0, 'high': 1.0, 'friday': 1.0, 'stay': 1.0, 'oil': 1.0, 'price': 1.0, 'surge': 1.0, 'past': 1.0, '<num>': 1.3010299956639813, 'barrel': 1.0, 'offset': 1.0, 'positive': 1.0, 'outlook': 1.0, 'computer': 1.0, 'maker': 1.0, 'dell': 1.0, 'inc': 1.0, 'dello': 1.0}\n",
      "{'money': 1.3010299956639813, 'fund': 1.3010299956639813, 'fell': 1.3010299956639813, 'late': 1.3010299956639813, 'week': 1.3010299956639813, 'ap': 1.3010299956639813, 'asset': 1.0, 'retail': 1.0, 'market': 1.0, 'mutual': 1.0, '<num>': 1.7781512503836436, 'billion': 1.0, 'trillion': 1.0, 'investment': 1.0, 'company': 1.0, 'institute': 1.0, 'say': 1.0, 'thursday': 1.0}\n",
      "{'feed': 1.0, 'minute': 1.0, 'dissent': 1.0, 'inflation': 1.0, 'usatodaycom': 1.3010299956639813, 'retail': 1.0, 'sale': 1.0, 'bounce': 1.0, 'bit': 1.0, 'july': 1.0, 'new': 1.0, 'claim': 1.0, 'jobless': 1.0, 'benefit': 1.0, 'fell': 1.0, 'week': 1.0, 'government': 1.0, 'say': 1.0, 'thursday': 1.0, 'indicate': 1.0, 'economy': 1.0, 'improve': 1.0, 'midsummer': 1.0, 'slump': 1.0}\n",
      "{'safety': 1.0, 'net': 1.0, 'forbescom': 1.3010299956639813, 'earn': 1.0, 'phd': 1.0, 'sociology': 1.0, 'danny': 1.0, 'bazil': 1.0, 'riley': 1.3010299956639813, 'start': 1.0, 'work': 1.0, 'general': 1.0, 'manager': 1.0, 'commercial': 1.0, 'real': 1.0, 'estate': 1.0, 'firm': 1.0, 'annual': 1.0, 'base': 1.0, 'salary': 1.0, '<num>': 1.6020599913279625, 'soon': 1.0, 'financial': 1.0, 'planner': 1.0, 'stop': 1.0, 'desk': 1.0, 'drop': 1.0, 'brochures': 1.0, 'insurance': 1.3010299956639813, 'benefit': 1.0, 'available': 1.0, 'employer': 1.0, 'buying': 1.0, 'furthest': 1.0, 'thing': 1.0, 'mind': 1.0, 'say': 1.0}\n",
      "{'wall': 1.3010299956639813, 'st': 1.0, 'bear': 1.0, 'claw': 1.0, 'black': 1.0, 'new': 1.0, 'york': 1.0, 'reuters': 1.0, 'short': 1.0, 'seller': 1.0, 'dwindle': 1.0, 'band': 1.0, 'ultra': 1.0, 'cynic': 1.0, 'see': 1.0, 'green': 1.0}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in TF:\n",
    "    if counter < 10:\n",
    "        print(i)\n",
    "        counter += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297b9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(dft, df_tokens_len):\n",
    "    return math.log10(df_tokens_len / dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dcb11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF = {word: compute_idf(dft, len(df[\"tokens\"])) for word, dft in vocabulary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270c51cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall: 1.9030899869919435\n",
      "st: 1.8541305499095762\n",
      "bear: 2.2206440484779857\n",
      "claw: 3.5228787452803374\n",
      "black: 2.1569749686086084\n",
      "reuters: 0.8418889084801661\n",
      "short: 2.113509274827518\n",
      "seller: 3.057991946977687\n",
      "dwindle: 3.3979400086720375\n",
      "band: 2.6989700043360187\n",
      "ultra: 3.170696227168975\n",
      "cynic: 4.301029995663981\n",
      "see: 1.809434872916858\n",
      "green: 2.1426675035687315\n",
      "carlyle: 3.8750612633917\n",
      "look: 1.6342001339596801\n",
      "commercial: 2.3459839809410554\n",
      "aerospace: 2.968591535748376\n",
      "private: 2.2212459813281957\n",
      "investment: 2.0853043311064137\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key, value in IDF.items():\n",
    "    if counter < 20:\n",
    "        print(f\"{key}: {value}\")\n",
    "        counter += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a653db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "indices = []\n",
    "indptr = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ef57dc-c3ce-45e8-bf99-eca62289fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(IDF.keys())\n",
    "word_to_index = {word: i for i, word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3e0093-9012-4c1c-a437-55b3b9ce6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TF)):\n",
    "    for word, tf in TF[i].items():\n",
    "        if word in IDF:\n",
    "            tf_idf = tf * IDF[word]\n",
    "            data.append(tf_idf)\n",
    "            indices.append((df[\"label\"][i] - 1) * len(IDF) + word_to_index[word])\n",
    "    indptr.append(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b44abd87-95bc-451e-9d4c-5e5b849c7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = csr_matrix((data, indices, indptr), shape=(len(TF), len(IDF) * 4), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c5ed590-c08f-4037-b37e-ac2e82ff073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 116296)\t2.4759771575242944\n",
      "  (0, 116297)\t1.8541305499095762\n",
      "  (0, 116298)\t2.2206440484779857\n",
      "  (0, 116299)\t3.5228787452803374\n",
      "  (0, 116300)\t2.1569749686086084\n",
      "  (0, 116301)\t1.0953227229495044\n",
      "  (0, 116302)\t2.113509274827518\n",
      "  (0, 116303)\t3.057991946977687\n",
      "  (0, 116304)\t3.3979400086720375\n",
      "  (0, 116305)\t2.6989700043360187\n",
      "  (0, 116306)\t3.170696227168975\n",
      "  (0, 116307)\t4.301029995663981\n",
      "  (0, 116308)\t1.809434872916858\n",
      "  (0, 116309)\t2.1426675035687315\n",
      "  (1, 116310)\t5.0415709387081655\n",
      "  (1, 116311)\t1.6342001339596801\n",
      "  (1, 116312)\t2.3459839809410554\n",
      "  (1, 116313)\t2.968591535748376\n",
      "  (1, 116301)\t1.0953227229495044\n",
      "  (1, 116314)\t2.2212459813281957\n",
      "  (1, 116315)\t2.0853043311064137\n",
      "  (1, 116316)\t1.6824589675438515\n",
      "  (1, 116317)\t1.3535962737769305\n",
      "  (1, 116318)\t2.9822712330395684\n",
      "  (1, 116319)\t1.4116349065361085\n",
      "  :\t:\n",
      "  (119998, 65816)\t2.8916605252111616\n",
      "  (119998, 58900)\t1.7262273343375372\n",
      "  (119998, 58393)\t1.432875565762866\n",
      "  (119998, 58234)\t0.9259458273953294\n",
      "  (119998, 59223)\t2.1337126609158052\n",
      "  (119999, 58282)\t2.466267213451721\n",
      "  (119999, 62545)\t3.483873019361422\n",
      "  (119999, 67950)\t3.5977564948380083\n",
      "  (119999, 67633)\t2.603510057723195\n",
      "  (119999, 59373)\t1.8484769324350558\n",
      "  (119999, 87465)\t3.070581074285707\n",
      "  (119999, 58361)\t1.6635402661514704\n",
      "  (119999, 62811)\t2.125421554314396\n",
      "  (119999, 58218)\t0.7450493137197958\n",
      "  (119999, 62129)\t2.6847295652214087\n",
      "  (119999, 80873)\t3.466397389327889\n",
      "  (119999, 63978)\t2.7632109005907073\n",
      "  (119999, 61393)\t3.010995384301463\n",
      "  (119999, 62542)\t2.688375553127465\n",
      "  (119999, 65717)\t3.0\n",
      "  (119999, 59472)\t2.5016894462103996\n",
      "  (119999, 61982)\t1.7858186913361793\n",
      "  (119999, 63558)\t2.505149978319906\n",
      "  (119999, 59010)\t2.1760912590556813\n",
      "  (119999, 60283)\t1.2980005251103632\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445abde2-ddeb-497a-bf33-044f5d3e3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf_idf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80140590-2fe1-4504-843c-f9cd3051a46b",
   "metadata": {},
   "source": [
    "## 3.构建并训练Log-Linear模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14e4ea6-f817-45bf-8020-e7eee17f328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLinearModel:\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.weights = np.zeros((n_classes, n_features))\n",
    "\n",
    "    def train(self,X,y,lr=0.01,epochs=10):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(len(X)):\n",
    "                scores = X[i] @ self.weights.T\n",
    "                probs = self.mysoftmax(scores)\n",
    "\n",
    "                delta=np.outer(probs-y[i],X[i])\n",
    "                self.weights -= lr*delta\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4caeb703-41ab-4b6a-9f5e-a436b00b0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"label\"]\n",
    "lambda_vector = np.random.randn(tf_idf.shape[1]) * 0.01\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "num_docs = len(TF)\n",
    "num_words = len(IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d11af8de-9495-4223-a7e1-f1edd3678b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_i(word_index, doc_index, label):\n",
    "    return tf_idf[doc_index][(label - 1) * num_words + word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ef2debb-6f84-4100-9677-3e3767a8fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(doc_index, label):\n",
    "    return np.exp(f_i(document, label).dot(lambda_vector)[0]) / np.exp(\n",
    "        [f_i(document, label).dot(lambda_vector)[0] for label_prime in range(1, 5)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2590d0f-9dd9-43a5-829b-5753514486a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(batch_indices):\n",
    "    return [\n",
    "        np.sum([tf_idf[doc_index][lambda_index] for doc_index in range(num_docs)])\n",
    "        - np.sum(\n",
    "            [\n",
    "                np.sum(f_i(tf_idf[doc_index], label_prime))\n",
    "                * p(tf_idf[doc_index], label_prime)\n",
    "                for label_prime in range(1, 5)\n",
    "            ]\n",
    "        )\n",
    "        for lambda_index in range(tf_idf.shape[1])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f819dff-5228-4461-a08d-7725f1c108c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood():\n",
    "    return np.sum(\n",
    "        [f_i(tf_idf[doc_index], labels[doc_index]).dot(lambda_vector)[0]]\n",
    "        for doc_index in range(num_docs)\n",
    "    ) - np.sum(\n",
    "        [\n",
    "            np.log10(\n",
    "                np.sum(\n",
    "                    [\n",
    "                        f_i(tf_idf[doc_index], label_prime).dot(lambda_vector)[0]\n",
    "                        for label_prime in range(1, 5)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            for doc_index in range(num_docs)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6da5e406-cf87-4602-ab8f-91769338b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae0fd7ee1d64cf8a54e10d733ea4735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4a15c89fcc4df1a2554b03aba8010e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batchs:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 232592)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (232592,) (128,) (232592,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     batch_indices \u001b[38;5;241m=\u001b[39m shuffled_indices[start_idx:end_idx]\n\u001b[0;32m      8\u001b[0m     grad \u001b[38;5;241m=\u001b[39m gradient(batch_indices)\n\u001b[1;32m----> 9\u001b[0m     lambda_vector \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(grad)\n\u001b[0;32m     11\u001b[0m ll \u001b[38;5;241m=\u001b[39m log_likelihood()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Log-Likelihood: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mll\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (232592,) (128,) (232592,) "
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    shuffled_indices = np.random.permutation(num_docs)\n",
    "\n",
    "    for start_idx in tqdm(range(0, num_docs, batch_size), desc=\"Batchs\", leave=False):\n",
    "        end_idx = min(start_idx + batch_size, num_docs)\n",
    "        batch_indices = shuffled_indices[start_idx:end_idx]\n",
    "\n",
    "        grad = gradient(batch_indices)\n",
    "        lambda_vector += lr * np.array(grad)\n",
    "\n",
    "    ll = log_likelihood()\n",
    "    print(f\"Epoch {t + 1}/{epochs}, Log-Likelihood: {ll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a166c770-8167-4ef4-a3e1-4542be05f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58148,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"lambda.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lambda_vector, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba3da44-c369-4f3b-a455-72a9edd5be2e",
   "metadata": {},
   "source": [
    "## 4.测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a81fe4-feff-4f1b-8fdd-4f4aaede732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(lambda_vector, tf_idf):\n",
    "    scores = tf_idf.dot(lambda_vector)\n",
    "    probs = softmax(scores)\n",
    "    return np.argmax(probs, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bdae433-1c66-487c-8121-b73b5a5c090a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 58148)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e659a50-6efd-4b16-951a-897ef8c604d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.nonzero(tf_idf[1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea6f6d-dac2-4889-8207-6f6faafd84ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
